{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "brOJbztdiOsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnu4kG2RTcQw",
        "outputId": "b0186390-c3b7-4c56-8114-1da66aa28b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1a51b28"
      },
      "source": [
        "### Célula 1: Montando o Google Drive\n",
        "Esta célula importa a biblioteca `drive` do `google.colab` e a usa para montar seu Google Drive no ambiente do Colab. Isso permite que o notebook acesse arquivos armazenados em seu Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7797a3f"
      },
      "source": [
        "### Célula 2: Copiando o arquivo ZIP\n",
        "Esta célula usa um comando shell (`!cp`) para copiar um arquivo ZIP chamado `nfl-big-data-bowl-2026-prediction.zip` de uma pasta específica no seu Google Drive (`/content/drive/MyDrive/'Colab Notebooks'/`) para o diretório raiz do ambiente Colab (`/content/`). Isso é necessário para descompactar o arquivo no ambiente local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c1a6750"
      },
      "source": [
        "### Célula 3: Descompactando o arquivo\n",
        "Esta célula usa um comando shell (`!unzip`) para descompactar o arquivo `nfl-big-data-bowl-2026-prediction.zip` que foi copiado para `/content/`. A saída mostra todos os arquivos e diretórios que foram extraídos, incluindo dados de treinamento (`train/input_*.csv`, `train/output_*.csv`) e arquivos de avaliação (`test.csv`, `kaggle_evaluation/`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04e274a4"
      },
      "source": [
        "### Célula 4: Listando arquivos de treinamento\n",
        "Esta célula usa um comando shell (`!ls`) para listar o conteúdo do diretório `/content/train`. Isso serve para verificar se os arquivos de entrada e saída do conjunto de treinamento foram descompactados corretamente e estão acessíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9412172d"
      },
      "source": [
        "### Célula 5: Pré-processamento, Engenharia de Features e Treinamento do Modelo\n",
        "Esta é a célula principal que realiza a maior parte do trabalho, desde o carregamento dos dados até o treinamento do modelo. Vamos dividi-la em seções:\n",
        "\n",
        "#### 5.1. Importações e Carregamento de Dados\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for f in glob.glob(\"/content/train/input_*.csv\"):\n",
        "    inputs.append(pd.read_csv(f))\n",
        "\n",
        "for f in glob.glob(\"/content/train/output_*.csv\"):\n",
        "    outputs.append(pd.read_csv(f))\n",
        "\n",
        "input_df = pd.concat(inputs, ignore_index=True)\n",
        "output_df = pd.concat(outputs, ignore_index=True)\n",
        "```\n",
        "*   **Importações**: Importa bibliotecas essenciais como `pandas` para manipulação de dados, `numpy` para operações numéricas, `glob` para encontrar arquivos, e classes do `sklearn` e `xgboost` para modelagem.\n",
        "*   **Carregamento e Concatenação**: O código itera sobre todos os arquivos `input_*.csv` e `output_*.csv` no diretório `/content/train`, lê cada um deles para um DataFrame e os concatena em `input_df` e `output_df` respectivamente. Esses DataFrames contêm os dados de entrada (posições dos jogadores, velocidade, etc.) e os dados de saída (posições alvo x e y da bola, número de frames futuros) para cada jogada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "992ddc7a"
      },
      "source": [
        "#### 5.2. Engenharia de Features de Lag\n",
        "```python\n",
        "input_df = input_df.sort_values(\n",
        "    [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]\n",
        ")\n",
        "\n",
        "for lag in [1,2,3,5]:\n",
        "    input_df[f\"x_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"x\"].shift(lag)\n",
        "\n",
        "    input_df[f\"y_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"y\"].shift(lag)\n",
        "\n",
        "    input_df[f\"s_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"s\"].shift(lag)\n",
        "```\n",
        "*   **Ordenação**: O `input_df` é ordenado por `game_id`, `play_id`, `nfl_id` e `frame_id` para garantir que as operações de `shift` (lag) funcionem corretamente.\n",
        "*   **Recursos de Lag**: São criadas novas features (`x_lag`, `y_lag`, `s_lag`) que representam os valores de `x`, `y` e `s` (velocidade) de frames anteriores. Isso é feito agrupando por `game_id`, `play_id` e `nfl_id` para garantir que o lag seja aplicado dentro do contexto de cada jogador em cada jogada, e usando `shift()` com diferentes valores de `lag` (1, 2, 3 e 5 frames)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbab1262"
      },
      "source": [
        "#### 5.3. Preparação dos Dados para Treinamento\n",
        "```python\n",
        "key = [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "\n",
        "last_input = (\n",
        "    input_df\n",
        "    .loc[\n",
        "        input_df.groupby(key)[\"frame_id\"].idxmax()\n",
        "    ]\n",
        ")\n",
        "\n",
        "df = output_df.merge(\n",
        "    last_input,\n",
        "    on=key,\n",
        "    suffixes=(\"_target\",\"_input\")\n",
        ")\n",
        "df[\"k\"] = df[\"frame_id_target\"]\n",
        "```\n",
        "*   **`last_input`**: Seleciona a última entrada de `frame_id` para cada combinação única de `game_id`, `play_id` e `nfl_id` no `input_df`.\n",
        "*   **Junção (Merge)**: O `output_df` é mesclado com `last_input` usando `game_id`, `play_id` e `nfl_id` como chaves. Os sufixos `_target` e `_input` são adicionados para diferenciar colunas com nomes semelhantes que vêm de `output_df` e `last_input`, respectivamente. `df['k']` é criado a partir de `frame_id_target` (que representa o número de frames à frente que estamos prevendo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b920ee1"
      },
      "source": [
        "#### 5.4. Mais Engenharia de Features\n",
        "```python\n",
        "df[\"dt\"] = df[\"num_frames_output\"]\n",
        "df[\"dx\"] = df[\"x_target\"] - df[\"x_input\"]\n",
        "df[\"dy\"] = df[\"y_target\"] - df[\"y_input\"]\n",
        "df[\"dir_rad\"] = np.deg2rad(df[\"dir\"])\n",
        "df[\"vx\"] = df[\"s\"] * np.cos(df[\"dir_rad\"])\n",
        "df[\"vy\"] = df[\"s\"] * np.sin(df[\"dir_rad\"])\n",
        "df[\"k2\"] = df[\"k\"]**2\n",
        "df[\"vx_k\"] = df[\"vx\"] * df[\"k\"]\n",
        "df[\"vy_k\"] = df[\"vy\"] * df[\"k\"]\n",
        "df[\"a_k2\"] = df[\"a\"] * df[\"k\"]**2\n",
        "df[\"o_rad\"] = np.deg2rad(df[\"o\"])\n",
        "df[\"ox\"] = np.cos(df[\"o_rad\"])\n",
        "df[\"oy\"] = np.sin(df[\"o_rad\"])\n",
        "\n",
        "# Vetor até a bola\n",
        "df[\"dist_ball_x\"] = df[\"ball_land_x\"] - df[\"x_input\"]\n",
        "df[\"dist_ball_y\"] = df[\"ball_land_y\"] - df[\"y_input\"]\n",
        "\n",
        "# Distância\n",
        "df[\"dist_ball\"] = np.sqrt(\n",
        "    df[\"dist_ball_x\"]**2 + df[\"dist_ball_y\"]**2\n",
        ")\n",
        "\n",
        "# Ângulo até a bola\n",
        "df[\"angle_ball\"] = np.arctan2(\n",
        "    df[\"dist_ball_y\"],\n",
        "    df[\"dist_ball_x\"]\n",
        ")\n",
        "\n",
        "# Alinhamento com velocidade\n",
        "df[\"dot_ball_vel\"] = (\n",
        "    df[\"dist_ball_x\"] * df[\"vx\"] +\n",
        "    df[\"dist_ball_y\"] * df[\"vy\"]\n",
        ")\n",
        "```\n",
        "*   **Diferenças e Velocidades**: Calcula a diferença nas posições (`dx`, `dy`), converte direção (`dir`) e orientação (`o`) para radianos e componentes X/Y (`vx`, `vy`, `ox`, `oy`).\n",
        "*   **Features de Tempo**: Cria `k2`, `vx_k`, `vy_k`, `a_k2` que envolvem o número de frames futuros `k`.\n",
        "*   **Relação com a Bola**: Calcula a distância e o ângulo do jogador em relação ao ponto de aterrissagem da bola (`ball_land_x`, `ball_land_y`), além do produto escalar do vetor para a bola com o vetor velocidade do jogador (`dot_ball_vel`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "444f791d"
      },
      "source": [
        "#### 5.5. Tratamento de Variáveis Categóricas e Altura\n",
        "```python\n",
        "cat_cols = [\n",
        "    \"player_position\",\n",
        "    \"player_role\",\n",
        "    \"player_side\",\n",
        "    \"play_direction\"\n",
        "]\n",
        "def height_to_inches(h):\n",
        "    try:\n",
        "        feet, inch = h.split(\"-\")\n",
        "        return int(feet)*12 + int(inch)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"player_height_in\"] = df[\"player_height\"].apply(height_to_inches)\n",
        "\n",
        "df[\"player_height_in\"] = df[\"player_height_in\"].fillna(\n",
        "    df[\"player_height_in\"].median()\n",
        ")\n",
        "for c in cat_cols:\n",
        "    df[c] = df[c].astype(\"category\").cat.codes\n",
        "```\n",
        "*   **`height_to_inches`**: Uma função para converter a altura do jogador (formatada como \"pés-polegadas\") para polegadas. Lida com possíveis erros retornando `NaN`.\n",
        "*   **Preenchimento de Nulos**: Valores `NaN` na altura são preenchidos com a mediana da coluna.\n",
        "*   **Codificação Categórica**: As colunas categóricas (`player_position`, `player_role`, `player_side`, `play_direction`) são convertidas para códigos numéricos usando `astype(\"category\").cat.codes`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd8c5261"
      },
      "source": [
        "#### 5.6. Definição de Features e Variáveis Alvo\n",
        "```python\n",
        "features = [\n",
        "    \"x_input\",\"y_input\",\n",
        "    \"vx\",\"vy\",\"a\",\"k\",\"k2\",\"vx_k\",\"vy_k\",\"a_k2\",\n",
        "    \"o_rad\",\"ox\",\"oy\",\n",
        "    \"player_weight\",\n",
        "     \"player_height_in\",\n",
        "    \"player_position\",\n",
        "    \"player_role\",\n",
        "    \"player_side\",\n",
        "    \"play_direction\",\n",
        "    \"x_lag1\",\"x_lag2\",\"x_lag3\",\"x_lag5\",\n",
        "    \"y_lag1\",\"y_lag2\",\"y_lag3\",\"y_lag5\",\n",
        "    \"s_lag1\",\"s_lag2\",\"s_lag3\",\"s_lag5\",\n",
        "      \"ball_land_x\",\n",
        "    \"ball_land_y\",\n",
        "    \"dist_ball_x\",\n",
        "    \"dist_ball_y\",\n",
        "    \"dist_ball\",\n",
        "    \"angle_ball\",\n",
        "    \"dot_ball_vel\"\n",
        "\n",
        "]\n",
        "\n",
        "df[\"dx_n\"] = df[\"dx\"] / df[\"k\"]\n",
        "df[\"dy_n\"] = df[\"dy\"] / df[\"k\"]\n",
        "\n",
        "y = df[[\"dx_n\",\"dy_n\"]]\n",
        "groups = (\n",
        "    df[\"game_id\"].astype(str)\n",
        "    + \"_\"\n",
        "    + df[\"play_id\"].astype(str)\n",
        ")\n",
        "```\n",
        "*   **`features`**: Uma lista de todas as colunas que serão usadas como features para o modelo, incluindo as originais e as engenheiradas.\n",
        "*   **Variáveis Alvo Normalizadas**: `dx_n` e `dy_n` são calculadas dividindo `dx` e `dy` por `k` (o número de frames futuros). Isso normaliza o deslocamento pela duração da previsão, tornando o problema de regressão mais estável.\n",
        "*   **`y`**: O DataFrame das variáveis alvo normalizadas (`dx_n`, `dy_n`).\n",
        "*   **`groups`**: Uma string que combina `game_id` e `play_id`. Isso é usado para `GroupKFold` na validação cruzada para garantir que os dados de uma mesma jogada (`game_id`, `play_id`) não sejam divididos entre os conjuntos de treino e validação, evitando vazamento de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8baa6862"
      },
      "source": [
        "#### 5.7. Ajuste para Direção da Jogada\n",
        "```python\n",
        "left = df[\"play_direction\"] == \"left\"\n",
        "df.loc[left, \"ball_land_x\"] = 120 - df.loc[left, \"ball_land_x\"]\n",
        "\n",
        "\n",
        "for col in [\"x_input\",\"x_lag1\",\"x_lag2\",\"x_lag3\",\"x_lag5\"]:\n",
        "    df.loc[left, col] = 120 - df.loc[left, col]\n",
        "\n",
        "df.loc[left, \"vx\"] *= -1\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "```\n",
        "*   **Inversão para Lado Esquerdo**: Para jogadas que se movem para a esquerda, as coordenadas X (incluindo `ball_land_x`, `x_input`, e `x_lag` features) são invertidas em relação ao comprimento do campo (120 jardas). A velocidade `vx` também é invertida. Isso é uma técnica comum para padronizar a direção do campo, tratando jogadas para a esquerda e para a direita de forma simétrica e simplificando o aprendizado do modelo.\n",
        "*   **`X`**: O DataFrame final das features para o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a6ebea6"
      },
      "source": [
        "#### 5.8. Métrica de Avaliação\n",
        "```python\n",
        "def metric(y_true, y_pred):\n",
        "    return np.sqrt(\n",
        "        np.mean(\n",
        "            (y_true[:,0]-y_pred[:,0])**2 +\n",
        "            (y_true[:,1]-y_pred[:,1])**2\n",
        "        ) / 2\n",
        "    )\n",
        "```\n",
        "*   Define uma função `metric` que calcula a raiz do erro quadrático médio (RMSE) para duas dimensões (x e y), dividido por 2. Esta métrica avalia a distância euclidiana média entre as previsões e os valores reais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad436cc3"
      },
      "source": [
        "#### 5.9. Validação Cruzada e Treinamento do Modelo\n",
        "```python\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for fold, (tr, va) in enumerate(gkf.split(X, y, groups)):\n",
        "\n",
        "    X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
        "\n",
        "    y_tr_x = y.iloc[tr, 0]   # dx\n",
        "    y_tr_y = y.iloc[tr, 1]   # dy\n",
        "\n",
        "    y_va_x = y.iloc[va, 0]\n",
        "    y_va_y = y.iloc[va, 1]\n",
        "\n",
        "    model_x = XGBRegressor(\n",
        "     n_estimators=2000,\n",
        "     max_depth=6,\n",
        "     learning_rate=0.05,\n",
        "     subsample=0.8,\n",
        "     colsample_bytree=0.8,\n",
        "     tree_method=\"hist\",\n",
        "     random_state=42,\n",
        "     eval_metric=\"rmse\",\n",
        "     early_stopping_rounds=50\n",
        "    )\n",
        "\n",
        "\n",
        "    model_y = XGBRegressor(\n",
        "      n_estimators=2000,\n",
        "      max_depth=6,\n",
        "      learning_rate=0.05,\n",
        "      subsample=0.8,\n",
        "      colsample_bytree=0.8,\n",
        "      tree_method=\"hist\",\n",
        "      random_state=42,\n",
        "      eval_metric=\"rmse\",\n",
        "      early_stopping_rounds=50\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "    # Treina separado\n",
        "    model_x.fit(\n",
        "    X_tr, y_tr_x,\n",
        "    eval_set=[(X_va, y_va_x)],\n",
        "\n",
        "    verbose=False\n",
        ")\n",
        "    model_y.fit(X_tr, y_tr_y,\n",
        "                eval_set=[(X_va, y_va_y)],\n",
        "                verbose=False)\n",
        "\n",
        "    # Prediz separado\n",
        "    pred_x = model_x.predict(X_va)\n",
        "    pred_y = model_y.predict(X_va)\n",
        "\n",
        "    # Junta\n",
        "    pred = np.column_stack([pred_x, pred_y])\n",
        "\n",
        "    k_val = df.iloc[va][\"k\"].values.reshape(-1,1)\n",
        "\n",
        "    pred_real = pred * k_val\n",
        "    y_real = df.iloc[va][[\"dx\",\"dy\"]].values\n",
        "\n",
        "    sc = metric(y_real, pred_real)\n",
        "    scores.append(sc)\n",
        "\n",
        "    print(f\"Fold {fold}: {sc:.4f}\")\n",
        "\n",
        "\n",
        "print(\"CV mean:\", np.mean(scores))\n",
        "```\n",
        "*   **GroupKFold**: Inicializa `GroupKFold` com 5 divisões. Isso garante que os dados de uma mesma jogada fiquem sempre no mesmo conjunto (treino ou validação) em cada fold, evitando vazamento de informação.\n",
        "*   **Loop de Validação Cruzada**: O código itera por cada fold:\n",
        "    *   Divide os dados em conjuntos de treino (`X_tr`, `y_tr`) e validação (`X_va`, `y_va`).\n",
        "    *   Separa as variáveis alvo `dx` e `dy` (normalizadas) para treinamento individual.\n",
        "    *   **Modelos XGBoost**: São criados dois modelos `XGBRegressor` idênticos, um para prever `dx_n` (`model_x`) e outro para `dy_n` (`model_y`).\n",
        "        *   Os parâmetros incluem `n_estimators` (número de árvores), `max_depth`, `learning_rate`, `subsample`, `colsample_bytree`, `tree_method=\"hist\"` (para desempenho), `random_state` e `early_stopping_rounds` (para parar o treinamento se o desempenho na validação não melhorar).\n",
        "    *   **Treinamento**: Cada modelo é treinado em seu respectivo alvo (`y_tr_x` ou `y_tr_y`), usando o conjunto de validação (`eval_set`) para monitorar o desempenho e aplicar o `early_stopping`.\n",
        "    *   **Previsão**: Após o treinamento, os modelos fazem previsões nos dados de validação (`pred_x`, `pred_y`).\n",
        "    *   **Reversão da Normalização**: As previsões normalizadas (`pred`) são multiplicadas de volta por `k_val` (o número de frames futuros) para obter os deslocamentos reais previstos (`pred_real`), que podem ser comparados com os deslocamentos reais `y_real` (`dx`, `dy`).\n",
        "    *   **Cálculo da Métrica**: A métrica de avaliação (`metric`) é calculada para o fold atual e adicionada à lista `scores`.\n",
        "    *   **Impressão dos Resultados**: Imprime a métrica para cada fold e, no final, a média das métricas de todos os folds (`CV mean`), fornecendo uma estimativa robusta do desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/'Colab Notebooks'/nfl-big-data-bowl-2026-prediction.zip /content/\n",
        "\n"
      ],
      "metadata": {
        "id": "FTl1_oO0Tyr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/nfl-big-data-bowl-2026-prediction.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LzrJSeZGXXhK",
        "outputId": "3f89b89e-ff02-4941-b0b4-37e3abc273d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nfl-big-data-bowl-2026-prediction.zip\n",
            "  inflating: kaggle_evaluation/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/base_gateway.py  \n",
            "  inflating: kaggle_evaluation/core/generated/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py  \n",
            "  inflating: kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py  \n",
            "  inflating: kaggle_evaluation/core/kaggle_evaluation.proto  \n",
            "  inflating: kaggle_evaluation/core/relay.py  \n",
            "  inflating: kaggle_evaluation/core/templates.py  \n",
            "  inflating: kaggle_evaluation/nfl_gateway.py  \n",
            "  inflating: kaggle_evaluation/nfl_inference_server.py  \n",
            "  inflating: test.csv                \n",
            "  inflating: test_input.csv          \n",
            "  inflating: train/input_2023_w01.csv  \n",
            "  inflating: train/input_2023_w02.csv  \n",
            "  inflating: train/input_2023_w03.csv  \n",
            "  inflating: train/input_2023_w04.csv  \n",
            "  inflating: train/input_2023_w05.csv  \n",
            "  inflating: train/input_2023_w06.csv  \n",
            "  inflating: train/input_2023_w07.csv  \n",
            "  inflating: train/input_2023_w08.csv  \n",
            "  inflating: train/input_2023_w09.csv  \n",
            "  inflating: train/input_2023_w10.csv  \n",
            "  inflating: train/input_2023_w11.csv  \n",
            "  inflating: train/input_2023_w12.csv  \n",
            "  inflating: train/input_2023_w13.csv  \n",
            "  inflating: train/input_2023_w14.csv  \n",
            "  inflating: train/input_2023_w15.csv  \n",
            "  inflating: train/input_2023_w16.csv  \n",
            "  inflating: train/input_2023_w17.csv  \n",
            "  inflating: train/input_2023_w18.csv  \n",
            "  inflating: train/output_2023_w01.csv  \n",
            "  inflating: train/output_2023_w02.csv  \n",
            "  inflating: train/output_2023_w03.csv  \n",
            "  inflating: train/output_2023_w04.csv  \n",
            "  inflating: train/output_2023_w05.csv  \n",
            "  inflating: train/output_2023_w06.csv  \n",
            "  inflating: train/output_2023_w07.csv  \n",
            "  inflating: train/output_2023_w08.csv  \n",
            "  inflating: train/output_2023_w09.csv  \n",
            "  inflating: train/output_2023_w10.csv  \n",
            "  inflating: train/output_2023_w11.csv  \n",
            "  inflating: train/output_2023_w12.csv  \n",
            "  inflating: train/output_2023_w13.csv  \n",
            "  inflating: train/output_2023_w14.csv  \n",
            "  inflating: train/output_2023_w15.csv  \n",
            "  inflating: train/output_2023_w16.csv  \n",
            "  inflating: train/output_2023_w17.csv  \n",
            "  inflating: train/output_2023_w18.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okpl_EYiXSj9",
        "outputId": "2ff5846b-b5db-45d9-c193-9746aaa75541",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_2023_w01.csv  input_2023_w13.csv\t output_2023_w07.csv\n",
            "input_2023_w02.csv  input_2023_w14.csv\t output_2023_w08.csv\n",
            "input_2023_w03.csv  input_2023_w15.csv\t output_2023_w09.csv\n",
            "input_2023_w04.csv  input_2023_w16.csv\t output_2023_w10.csv\n",
            "input_2023_w05.csv  input_2023_w17.csv\t output_2023_w11.csv\n",
            "input_2023_w06.csv  input_2023_w18.csv\t output_2023_w12.csv\n",
            "input_2023_w07.csv  output_2023_w01.csv  output_2023_w13.csv\n",
            "input_2023_w08.csv  output_2023_w02.csv  output_2023_w14.csv\n",
            "input_2023_w09.csv  output_2023_w03.csv  output_2023_w15.csv\n",
            "input_2023_w10.csv  output_2023_w04.csv  output_2023_w16.csv\n",
            "input_2023_w11.csv  output_2023_w05.csv  output_2023_w17.csv\n",
            "input_2023_w12.csv  output_2023_w06.csv  output_2023_w18.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for f in glob.glob(\"/content/train/input_*.csv\"):\n",
        "    inputs.append(pd.read_csv(f))\n",
        "\n",
        "for f in glob.glob(\"/content/train/output_*.csv\"):\n",
        "    outputs.append(pd.read_csv(f))\n",
        "\n",
        "input_df = pd.concat(inputs, ignore_index=True)\n",
        "output_df = pd.concat(outputs, ignore_index=True)\n",
        "\n",
        "input_df = input_df.sort_values(\n",
        "    [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]\n",
        ")\n",
        "\n",
        "for lag in [1,2,3,5]:\n",
        "    input_df[f\"x_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"x\"].shift(lag)\n",
        "\n",
        "    input_df[f\"y_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"y\"].shift(lag)\n",
        "\n",
        "    input_df[f\"s_lag{lag}\"] = input_df.groupby(\n",
        "        [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "    )[\"s\"].shift(lag)\n",
        "\n",
        "\n",
        "key = [\"game_id\",\"play_id\",\"nfl_id\"]\n",
        "\n",
        "last_input = (\n",
        "    input_df\n",
        "    .loc[\n",
        "        input_df.groupby(key)[\"frame_id\"].idxmax()\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "df = output_df.merge(\n",
        "    last_input,\n",
        "    on=key,\n",
        "    suffixes=(\"_target\",\"_input\")\n",
        ")\n",
        "df[\"k\"] = df[\"frame_id_target\"]\n",
        "\n",
        "df[[\"x_input\",\"x_target\"]].head()\n",
        "\n",
        "df[\"dt\"] = df[\"num_frames_output\"]\n",
        "df[\"dx\"] = df[\"x_target\"] - df[\"x_input\"]\n",
        "df[\"dy\"] = df[\"y_target\"] - df[\"y_input\"]\n",
        "df[\"dir_rad\"] = np.deg2rad(df[\"dir\"])\n",
        "df[\"vx\"] = df[\"s\"] * np.cos(df[\"dir_rad\"])\n",
        "df[\"vy\"] = df[\"s\"] * np.sin(df[\"dir_rad\"])\n",
        "df[\"k2\"] = df[\"k\"]**2\n",
        "df[\"vx_k\"] = df[\"vx\"] * df[\"k\"]\n",
        "df[\"vy_k\"] = df[\"vy\"] * df[\"k\"]\n",
        "df[\"a_k2\"] = df[\"a\"] * df[\"k\"]**2\n",
        "df[\"o_rad\"] = np.deg2rad(df[\"o\"])\n",
        "df[\"ox\"] = np.cos(df[\"o_rad\"])\n",
        "df[\"oy\"] = np.sin(df[\"o_rad\"])\n",
        "\n",
        "# Vetor até a bola\n",
        "df[\"dist_ball_x\"] = df[\"ball_land_x\"] - df[\"x_input\"]\n",
        "df[\"dist_ball_y\"] = df[\"ball_land_y\"] - df[\"y_input\"]\n",
        "\n",
        "# Distância\n",
        "df[\"dist_ball\"] = np.sqrt(\n",
        "    df[\"dist_ball_x\"]**2 + df[\"dist_ball_y\"]**2\n",
        ")\n",
        "\n",
        "# Ângulo até a bola\n",
        "df[\"angle_ball\"] = np.arctan2(\n",
        "    df[\"dist_ball_y\"],\n",
        "    df[\"dist_ball_x\"]\n",
        ")\n",
        "\n",
        "# Alinhamento com velocidade\n",
        "df[\"dot_ball_vel\"] = (\n",
        "    df[\"dist_ball_x\"] * df[\"vx\"] +\n",
        "    df[\"dist_ball_y\"] * df[\"vy\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "cat_cols = [\n",
        "    \"player_position\",\n",
        "    \"player_role\",\n",
        "    \"player_side\",\n",
        "    \"play_direction\"\n",
        "]\n",
        "def height_to_inches(h):\n",
        "    try:\n",
        "        feet, inch = h.split(\"-\")\n",
        "        return int(feet)*12 + int(inch)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"player_height_in\"] = df[\"player_height\"].apply(height_to_inches)\n",
        "\n",
        "df[\"player_height_in\"] = df[\"player_height_in\"].fillna(\n",
        "    df[\"player_height_in\"].median()\n",
        ")\n",
        "for c in cat_cols:\n",
        "    df[c] = df[c].astype(\"category\").cat.codes\n",
        "features = [\n",
        "    \"x_input\",\"y_input\",\n",
        "    \"vx\",\"vy\",\"a\",\"k\",\"k2\",\"vx_k\",\"vy_k\",\"a_k2\",\n",
        "    \"o_rad\",\"ox\",\"oy\",\n",
        "    \"player_weight\",\n",
        "     \"player_height_in\",\n",
        "    \"player_position\",\n",
        "    \"player_role\",\n",
        "    \"player_side\",\n",
        "    \"play_direction\",\n",
        "    \"x_lag1\",\"x_lag2\",\"x_lag3\",\"x_lag5\",\n",
        "    \"y_lag1\",\"y_lag2\",\"y_lag3\",\"y_lag5\",\n",
        "    \"s_lag1\",\"s_lag2\",\"s_lag3\",\"s_lag5\",\n",
        "      \"ball_land_x\",\n",
        "    \"ball_land_y\",\n",
        "    \"dist_ball_x\",\n",
        "    \"dist_ball_y\",\n",
        "    \"dist_ball\",\n",
        "    \"angle_ball\",\n",
        "    \"dot_ball_vel\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "df[\"dx_n\"] = df[\"dx\"] / df[\"k\"]\n",
        "df[\"dy_n\"] = df[\"dy\"] / df[\"k\"]\n",
        "\n",
        "y = df[[\"dx_n\",\"dy_n\"]]\n",
        "groups = (\n",
        "    df[\"game_id\"].astype(str)\n",
        "    + \"_\"\n",
        "    + df[\"play_id\"].astype(str)\n",
        ")\n",
        "\n",
        "\n",
        "left = df[\"play_direction\"] == \"left\"\n",
        "df.loc[left, \"ball_land_x\"] = 120 - df.loc[left, \"ball_land_x\"]\n",
        "\n",
        "\n",
        "for col in [\"x_input\",\"x_lag1\",\"x_lag2\",\"x_lag3\",\"x_lag5\"]:\n",
        "    df.loc[left, col] = 120 - df.loc[left, col]\n",
        "\n",
        "df.loc[left, \"vx\"] *= -1\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "def metric(y_true, y_pred):\n",
        "    return np.sqrt(\n",
        "        np.mean(\n",
        "            (y_true[:,0]-y_pred[:,0])**2 +\n",
        "            (y_true[:,1]-y_pred[:,1])**2\n",
        "        ) / 2\n",
        "    )\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for fold, (tr, va) in enumerate(gkf.split(X, y, groups)):\n",
        "\n",
        "    X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
        "\n",
        "    y_tr_x = y.iloc[tr, 0]   # dx\n",
        "    y_tr_y = y.iloc[tr, 1]   # dy\n",
        "\n",
        "    y_va_x = y.iloc[va, 0]\n",
        "    y_va_y = y.iloc[va, 1]\n",
        "\n",
        "    model_x = XGBRegressor(\n",
        "     n_estimators=2000,\n",
        "     max_depth=6,\n",
        "     learning_rate=0.05,\n",
        "     subsample=0.8,\n",
        "     colsample_bytree=0.8,\n",
        "     tree_method=\"hist\",\n",
        "     random_state=42,\n",
        "     eval_metric=\"rmse\",\n",
        "     early_stopping_rounds=50\n",
        "    )\n",
        "\n",
        "\n",
        "    model_y = XGBRegressor(\n",
        "      n_estimators=2000,\n",
        "      max_depth=6,\n",
        "      learning_rate=0.05,\n",
        "      subsample=0.8,\n",
        "      colsample_bytree=0.8,\n",
        "      tree_method=\"hist\",\n",
        "      random_state=42,\n",
        "      eval_metric=\"rmse\",\n",
        "      early_stopping_rounds=50\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "    # Treina separado\n",
        "    model_x.fit(\n",
        "    X_tr, y_tr_x,\n",
        "    eval_set=[(X_va, y_va_x)],\n",
        "\n",
        "    verbose=False\n",
        ")\n",
        "    model_y.fit(X_tr, y_tr_y,\n",
        "                eval_set=[(X_va, y_va_y)],\n",
        "                verbose=False)\n",
        "\n",
        "    # Prediz separado\n",
        "    pred_x = model_x.predict(X_va)\n",
        "    pred_y = model_y.predict(X_va)\n",
        "\n",
        "    # Junta\n",
        "    pred = np.column_stack([pred_x, pred_y])\n",
        "\n",
        "    k_val = df.iloc[va][\"k\"].values.reshape(-1,1)\n",
        "\n",
        "    pred_real = pred * k_val\n",
        "    y_real = df.iloc[va][[\"dx\",\"dy\"]].values\n",
        "\n",
        "    sc = metric(y_real, pred_real)\n",
        "    scores.append(sc)\n",
        "\n",
        "    print(f\"Fold {fold}: {sc:.4f}\")\n",
        "\n",
        "\n",
        "print(\"CV mean:\", np.mean(scores))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QxjKMa6wXl_N",
        "outputId": "cda9aefd-1a6f-4fc9-dbb7-b215a8b87f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: 1.4565\n",
            "Fold 1: 0.9392\n",
            "Fold 2: 0.8857\n",
            "Fold 3: 0.8618\n",
            "Fold 4: 0.8810\n",
            "CV mean: 1.0048338484670425\n"
          ]
        }
      ]
    }
  ]
}